{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class labels\n",
    "class_labels = ['area', 'heatmap', 'horizontal_bar', 'horizontal_interval', 'line', 'manhattan',\n",
    "               'map', 'pie', 'scatter', 'scatter-line', 'surface', 'venn', 'vertical_bar',\n",
    "               'vertical_box', 'vertical_interval']\n",
    "num_classes = len(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust paths to your train folder and class labels\n",
    "train_path = \"/kaggle/input/icpr-2022/ICPR 2022/ICPR2022_CHARTINFO_UB_PMC_TRAIN_v1.0/images\"\n",
    "\n",
    "# Data augmentation settings\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    classes = class_labels,\n",
    "    shuffle = False  \n",
    ")\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    train_datagen.filenames,\n",
    "    train_datagen.classes,\n",
    "    test_size=0.3,  # 30% for validation\n",
    "    stratify=train_datagen.classes  # Maintain class balance\n",
    ")\n",
    "\n",
    "test_generator = (val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.model import Model\n",
    "from keras.layers import Input,ConvLSTM2D,Dense,Dropout,GlobalAveragePooling2D,BatchNormalization,Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Gated Attention Block\n",
    "    def GatedAttentionBlock(spatial_inputs, num_features, red_coeff=8):\n",
    "        x = ConvLSTM2D(filters=(num_features//red_coeff), kernal_size=(3,3), padding=\"same\", return_sequences=True)(spatial_inputs)\n",
    "        x = ConvLSTM2D(filters=num_features, kernal_size=(3,3), padding=\"same\", return_sequences=True)(x)\n",
    "        AttMaps = Multiply()([spatial_inputs, x])\n",
    "        return AttMaps\n",
    "    \n",
    "    # MLP function\n",
    "    def mlp(x, embedding_dim, mlp_dim=256, drop_rate=0.2):\n",
    "        x = Dense(mlp_dim, activation='relu')(x)\n",
    "        x = Dropout(drop_rate)(x)\n",
    "        x = Dense(embedding_dim, activation='sigmoid')(x)\n",
    "        x = Dropout(drop_rate)(x)\n",
    "        return x\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = GatedAttentionBlock(x, x.get_Shape().as_list()[-1])\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = mlp(x, x.get_shape().as_list()[-1], mlp_dim=128, drop_rate=0.2)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the model\n",
    "model = get_model(input_shape, num_classes)\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs = 10,\n",
    "    validation_Data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "scores = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\",scores[0])\n",
    "print(\"Test Accuracy\", scores[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
